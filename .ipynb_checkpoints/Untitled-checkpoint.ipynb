{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf53a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Downloading protobuf-3.19.1-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-3.19.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentencepiece\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e57538c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5deafd014f44c0db1d3e3ca75461cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26852/326187720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mrm8488/t5-base-finetuned-emotion\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mrm8488/t5-base-finetuned-emotion\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\ailab\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ailab\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ailab\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ailab\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\ailab\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87239ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "def get_emotion(text):\n",
    "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\n",
    "\n",
    "  output = model.generate(input_ids=input_ids,\n",
    "               max_length=2)\n",
    "  \n",
    "  dec = [tokenizer.decode(ids) for ids in output]\n",
    "  label = dec[0].replace('<pad> ','')\n",
    "  return label\n",
    "  \n",
    "print(get_emotion(\"i feel as if i havent blogged in ages are at least truly blogged i am doing an update cute\")) # Output: 'joy'\n",
    "print(get_emotion(\"i have a feeling i kinda lost my best friend\")) # Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa09c386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28-000082</td>\n",
       "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
       "      <td>2020-01-28 08:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-10-000142</td>\n",
       "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
       "      <td>2020-02-10 23:45:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-15-000053</td>\n",
       "      <td>... [ I ] f it gets to the floor,</td>\n",
       "      <td>2020-02-15 14:12:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>2020-04-15-004470</td>\n",
       "      <td>anyone who violates the quarantine will be hel...</td>\n",
       "      <td>2020-04-15 21:27:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>2020-02-21-005024</td>\n",
       "      <td>Apple's anti-competitive behavior.</td>\n",
       "      <td>2020-02-21 06:08:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>2020-01-30-007507</td>\n",
       "      <td>Approximately 30% more precipitation can be ex...</td>\n",
       "      <td>2020-01-30 15:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>2020-01-30-007577</td>\n",
       "      <td>are looking at 2016 through a microscope and n...</td>\n",
       "      <td>2020-01-30 12:24:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>2020-04-02-004931</td>\n",
       "      <td>are people dreaming of some Wuhan-esc lockdown</td>\n",
       "      <td>2020-04-02 10:27:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  quoteID                                          quotation  \\\n",
       "0       2020-01-28-000082  [ D ] espite the efforts of the partners to cr...   \n",
       "1       2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "2       2020-02-10-000142  ... He (Madhav) also disclosed that the illega...   \n",
       "3       2020-02-15-000053                  ... [ I ] f it gets to the floor,   \n",
       "4       2020-01-24-000168  [ I met them ] when they just turned 4 and 7. ...   \n",
       "...                   ...                                                ...   \n",
       "499995  2020-04-15-004470  anyone who violates the quarantine will be hel...   \n",
       "499996  2020-02-21-005024                 Apple's anti-competitive behavior.   \n",
       "499997  2020-01-30-007507  Approximately 30% more precipitation can be ex...   \n",
       "499998  2020-01-30-007577  are looking at 2016 through a microscope and n...   \n",
       "499999  2020-04-02-004931     are people dreaming of some Wuhan-esc lockdown   \n",
       "\n",
       "                       date  \n",
       "0       2020-01-28 08:04:05  \n",
       "1       2020-01-16 12:00:13  \n",
       "2       2020-02-10 23:45:54  \n",
       "3       2020-02-15 14:12:51  \n",
       "4       2020-01-24 20:37:09  \n",
       "...                     ...  \n",
       "499995  2020-04-15 21:27:27  \n",
       "499996  2020-02-21 06:08:27  \n",
       "499997  2020-01-30 15:38:40  \n",
       "499998  2020-01-30 12:24:45  \n",
       "499999  2020-04-02 10:27:35  \n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv('./quotes_500k.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a33b085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28-000082</td>\n",
       "      <td>despite the efforts of the partners to create ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>department of homeland security was livid and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-10-000142</td>\n",
       "      <td>he madhav also disclosed that the illegal brib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-15-000053</td>\n",
       "      <td>if it gets to the floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>i met them when they just turned 4 and 7 they ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499988</th>\n",
       "      <td>2020-04-15-004470</td>\n",
       "      <td>anyone who violates the quarantine will be hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499989</th>\n",
       "      <td>2020-02-21-005024</td>\n",
       "      <td>apples anticompetitive behavior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>2020-01-30-007507</td>\n",
       "      <td>approximately 30 more precipitation can be exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>2020-01-30-007577</td>\n",
       "      <td>are looking at 2016 through a microscope and n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499992</th>\n",
       "      <td>2020-04-02-004931</td>\n",
       "      <td>are people dreaming of some wuhanesc lockdown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499993 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  quoteID                                          quotation\n",
       "0       2020-01-28-000082  despite the efforts of the partners to create ...\n",
       "1       2020-01-16-000088  department of homeland security was livid and ...\n",
       "2       2020-02-10-000142  he madhav also disclosed that the illegal brib...\n",
       "3       2020-02-15-000053                            if it gets to the floor\n",
       "4       2020-01-24-000168  i met them when they just turned 4 and 7 they ...\n",
       "...                   ...                                                ...\n",
       "499988  2020-04-15-004470  anyone who violates the quarantine will be hel...\n",
       "499989  2020-02-21-005024                    apples anticompetitive behavior\n",
       "499990  2020-01-30-007507  approximately 30 more precipitation can be exp...\n",
       "499991  2020-01-30-007577  are looking at 2016 through a microscope and n...\n",
       "499992  2020-04-02-004931      are people dreaming of some wuhanesc lockdown\n",
       "\n",
       "[499993 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv('./quotes_emotions.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4e1d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation_x</th>\n",
       "      <th>quotation_y</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28-000082</td>\n",
       "      <td>despite the efforts of the partners to create ...</td>\n",
       "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
       "      <td>2020-01-28 08:04:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>department of homeland security was livid and ...</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-10-000142</td>\n",
       "      <td>he madhav also disclosed that the illegal brib...</td>\n",
       "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
       "      <td>2020-02-10 23:45:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-15-000053</td>\n",
       "      <td>if it gets to the floor</td>\n",
       "      <td>... [ I ] f it gets to the floor,</td>\n",
       "      <td>2020-02-15 14:12:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>i met them when they just turned 4 and 7 they ...</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499988</th>\n",
       "      <td>2020-04-15-004470</td>\n",
       "      <td>anyone who violates the quarantine will be hel...</td>\n",
       "      <td>anyone who violates the quarantine will be hel...</td>\n",
       "      <td>2020-04-15 21:27:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499989</th>\n",
       "      <td>2020-02-21-005024</td>\n",
       "      <td>apples anticompetitive behavior</td>\n",
       "      <td>Apple's anti-competitive behavior.</td>\n",
       "      <td>2020-02-21 06:08:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499990</th>\n",
       "      <td>2020-01-30-007507</td>\n",
       "      <td>approximately 30 more precipitation can be exp...</td>\n",
       "      <td>Approximately 30% more precipitation can be ex...</td>\n",
       "      <td>2020-01-30 15:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499991</th>\n",
       "      <td>2020-01-30-007577</td>\n",
       "      <td>are looking at 2016 through a microscope and n...</td>\n",
       "      <td>are looking at 2016 through a microscope and n...</td>\n",
       "      <td>2020-01-30 12:24:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499992</th>\n",
       "      <td>2020-04-02-004931</td>\n",
       "      <td>are people dreaming of some wuhanesc lockdown</td>\n",
       "      <td>are people dreaming of some Wuhan-esc lockdown</td>\n",
       "      <td>2020-04-02 10:27:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499993 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  quoteID                                        quotation_x  \\\n",
       "0       2020-01-28-000082  despite the efforts of the partners to create ...   \n",
       "1       2020-01-16-000088  department of homeland security was livid and ...   \n",
       "2       2020-02-10-000142  he madhav also disclosed that the illegal brib...   \n",
       "3       2020-02-15-000053                            if it gets to the floor   \n",
       "4       2020-01-24-000168  i met them when they just turned 4 and 7 they ...   \n",
       "...                   ...                                                ...   \n",
       "499988  2020-04-15-004470  anyone who violates the quarantine will be hel...   \n",
       "499989  2020-02-21-005024                    apples anticompetitive behavior   \n",
       "499990  2020-01-30-007507  approximately 30 more precipitation can be exp...   \n",
       "499991  2020-01-30-007577  are looking at 2016 through a microscope and n...   \n",
       "499992  2020-04-02-004931      are people dreaming of some wuhanesc lockdown   \n",
       "\n",
       "                                              quotation_y                 date  \n",
       "0       [ D ] espite the efforts of the partners to cr...  2020-01-28 08:04:05  \n",
       "1       [ Department of Homeland Security ] was livid ...  2020-01-16 12:00:13  \n",
       "2       ... He (Madhav) also disclosed that the illega...  2020-02-10 23:45:54  \n",
       "3                       ... [ I ] f it gets to the floor,  2020-02-15 14:12:51  \n",
       "4       [ I met them ] when they just turned 4 and 7. ...  2020-01-24 20:37:09  \n",
       "...                                                   ...                  ...  \n",
       "499988  anyone who violates the quarantine will be hel...  2020-04-15 21:27:27  \n",
       "499989                 Apple's anti-competitive behavior.  2020-02-21 06:08:27  \n",
       "499990  Approximately 30% more precipitation can be ex...  2020-01-30 15:38:40  \n",
       "499991  are looking at 2016 through a microscope and n...  2020-01-30 12:24:45  \n",
       "499992     are people dreaming of some Wuhan-esc lockdown  2020-04-02 10:27:35  \n",
       "\n",
       "[499993 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv('./quotes_dates.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b431e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bigbo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# import contractions\n",
    "# from bs4 import BeautifulSoup\n",
    "# import unicodedata\n",
    "# import re\n",
    "# import numpy as np\n",
    "\n",
    "# REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "# BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "# from nltk.stem.porter import *\n",
    "# stemmer = PorterStemmer()\n",
    "#print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0eba17f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.10-py3-none-any.whl (322 kB)\n",
      "Collecting conllu>=4.0\n",
      "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
      "Collecting gdown==3.12.2\n",
      "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting huggingface-hub\n",
      "  Using cached huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from flair) (1.8.1)\n",
      "Collecting gensim>=3.4.0\n",
      "  Downloading gensim-4.1.2-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "Collecting more-itertools~=8.8.0\n",
      "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.6.4-cp38-cp38-win_amd64.whl (3.6 MB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "Collecting konoha<5.0.0,>=4.0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "konoha 4.6.5 requires requests<3.0.0,>=2.25.1, but you'll have requests 2.24.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from flair) (4.51.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from flair) (1.0.1)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from flair) (3.4.1)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.11.10-cp38-cp38-win_amd64.whl (273 kB)\n",
      "Collecting transformers>=4.0.0\n",
      "  Using cached transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from flair) (2.8.1)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from gdown==3.12.2->flair) (2.24.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from gdown==3.12.2->flair) (1.15.0)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from huggingface-hub->flair) (20.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from huggingface-hub->flair) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from torch!=1.8,>=1.5.0->flair) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (1.6.3)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (3.0.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.13.3-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (1.25.11)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.4.1)\n",
      "Collecting click\n",
      "  Using cached click-8.0.3-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from click->sacremoses->transformers>=4.0.0->flair) (0.4.4)\n",
      "Building wheels for collected packages: segtok, gdown, sqlitedict, wikipedia-api, langdetect, mpld3, ftfy, overrides\n",
      "  Building wheel for segtok (setup.py): started\n",
      "  Building wheel for segtok (setup.py): finished with status 'done'\n",
      "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25021 sha256=827d217fc7f5a1e6cdbf4b695aef91385ea8a0c4289abca75505e684fdfb29a4\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\36\\6d\\90\\6d9b11ba404f68f340ef3f6060cfdf9c9f34653b08eceeacf6\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9692 sha256=29b4ee8350ea554b3a114f3cd0968b78697b25381f0a36f4d6f3c8289503c69b\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\e2\\62\\1e\\926d1ebe7b1e733c78d627fd288d01b83feaf67efc06e0e4c3\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14381 sha256=f8bf598ae88ad88fc6fdfc8efb811fb8f38c57e323352c6cb7e47fa3867eaa18\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\92\\82\\8c\\54ef8d8770fd1a80938197e55d3ccd26eccd117f44c58f601b\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13467 sha256=469c231e40e3221a8e71372846df3c924776c0075a481054f59c1ef736b729a7\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\ed\\88\\e3\\da3d4d73cb91d659488cfa25913b84bbc26febec99d257bce9\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=c13bbd2848f7e180377c7fff7c911b0884bcf34dc4eda7d56cca378117d7ebac\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\13\\c7\\b0\\79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116683 sha256=4f5b0ab5f3df49c22897e1cd999cfc091ba999845eb1033e1f8441fe17718ff9\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\3d\\9f\\9d\\d806a20bd97bc7076d724fa3e69fa5be61836ba16b2ffa6126\n",
      "  Building wheel for ftfy (setup.py): started\n",
      "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
      "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41920 sha256=8216100ee390a6d33e40d9e53d6729cd6c94222164e39e3c12f276da8dffebf9\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\7f\\40\\63\\4bf603cec3ecc4a26985405834cb47eb8368bfa59e15dde046\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10179 sha256=6de318d9e4776c89437482156ed5044fc13eef388d6638106b683713f8494c51\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\6a\\4f\\72\\28857f75625b263e2e3f5ab2fc4416c0a85960ac6485007eaa\n",
      "Successfully built segtok gdown sqlitedict wikipedia-api langdetect mpld3 ftfy overrides\n",
      "Installing collected packages: conllu, regex, segtok, filelock, gdown, pyyaml, huggingface-hub, tabulate, sqlitedict, Cython, smart-open, gensim, wikipedia-api, more-itertools, lxml, langdetect, mpld3, overrides, importlib-metadata, konoha, sentencepiece, bpemb, janome, click, sacremoses, tokenizers, transformers, ftfy, wrapt, deprecated, flair\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\n",
      "Successfully installed Cython-0.29.23 bpemb-0.3.3 click-8.0.3 conllu-4.4.1 deprecated-1.2.13 filelock-3.4.0 flair-0.10 ftfy-6.0.3 gdown-3.12.2 gensim-4.1.2 huggingface-hub-0.2.1 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 lxml-4.6.4 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pyyaml-6.0 regex-2021.11.10 sacremoses-0.0.46 segtok-1.5.10 sentencepiece-0.1.95 smart-open-5.2.1 sqlitedict-1.7.0 tabulate-0.8.9 tokenizers-0.10.3 transformers-4.13.0 wikipedia-api-0.5.4 wrapt-1.13.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.0.58-py2.py3-none-any.whl (8.0 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
      "Building wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py): started\n",
      "  Building wheel for pyahocorasick (setup.py): finished with status 'done'\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp38-cp38-win_amd64.whl size=38901 sha256=494623af0e090d03fd9e03c5a9e59b90c538ac56f36997d499fc4fb9c7bed3fa\n",
      "  Stored in directory: c:\\users\\bigbo\\appdata\\local\\pip\\cache\\wheels\\74\\bc\\b8\\e5f739a84005620cfe66d3fcb8bb182e309d6056bc6700b60e\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.0 contractions-0.0.58 pyahocorasick-1.4.2 textsearch-0.0.21\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Collecting twython\n",
      "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from twython) (2.24.0)\n",
      "Collecting requests-oauthlib>=0.4.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests>=2.1.0->twython) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests>=2.1.0->twython) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests>=2.1.0->twython) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from requests>=2.1.0->twython) (2021.5.30)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, twython\n",
      "Successfully installed oauthlib-3.1.1 requests-oauthlib-1.3.0 twython-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install flair\n",
    "!pip install contractions\n",
    "!pip install beautifulsoup4\n",
    "!pip install twython\n",
    "# !pip install pyspark==3.0.2\n",
    "# !pip install pyspark\n",
    "# !pip install -U -q PyDrive\n",
    "# !apt install openjdk-8-jdk-headless -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31d72e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\bigbo\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.5\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b76ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_document(document):\n",
    "    document = ' '.join(word for word in document.split() if word.lower() not in STOPWORDS) \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c287c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quotation_x</th>\n",
       "      <th>quotation_y</th>\n",
       "      <th>date</th>\n",
       "      <th>quotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-28-000082</td>\n",
       "      <td>despite the efforts of the partners to create ...</td>\n",
       "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
       "      <td>2020-01-28 08:04:05</td>\n",
       "      <td>despite efforts partners create nonpolitical a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>department of homeland security was livid and ...</td>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>2020-01-16 12:00:13</td>\n",
       "      <td>department homeland security livid strongly ur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-10-000142</td>\n",
       "      <td>he madhav also disclosed that the illegal brib...</td>\n",
       "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
       "      <td>2020-02-10 23:45:54</td>\n",
       "      <td>madhav also disclosed illegal bribe amount col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-15-000053</td>\n",
       "      <td>if it gets to the floor</td>\n",
       "      <td>... [ I ] f it gets to the floor,</td>\n",
       "      <td>2020-02-15 14:12:51</td>\n",
       "      <td>gets floor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>i met them when they just turned 4 and 7 they ...</td>\n",
       "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
       "      <td>2020-01-24 20:37:09</td>\n",
       "      <td>met turned 4 7 little felt like fullblown step...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                        quotation_x  \\\n",
       "0  2020-01-28-000082  despite the efforts of the partners to create ...   \n",
       "1  2020-01-16-000088  department of homeland security was livid and ...   \n",
       "2  2020-02-10-000142  he madhav also disclosed that the illegal brib...   \n",
       "3  2020-02-15-000053                            if it gets to the floor   \n",
       "4  2020-01-24-000168  i met them when they just turned 4 and 7 they ...   \n",
       "\n",
       "                                         quotation_y                 date  \\\n",
       "0  [ D ] espite the efforts of the partners to cr...  2020-01-28 08:04:05   \n",
       "1  [ Department of Homeland Security ] was livid ...  2020-01-16 12:00:13   \n",
       "2  ... He (Madhav) also disclosed that the illega...  2020-02-10 23:45:54   \n",
       "3                  ... [ I ] f it gets to the floor,  2020-02-15 14:12:51   \n",
       "4  [ I met them ] when they just turned 4 and 7. ...  2020-01-24 20:37:09   \n",
       "\n",
       "                                           quotation  \n",
       "0  despite efforts partners create nonpolitical a...  \n",
       "1  department homeland security livid strongly ur...  \n",
       "2  madhav also disclosed illegal bribe amount col...  \n",
       "3                                         gets floor  \n",
       "4  met turned 4 7 little felt like fullblown step...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['quotation']=dataset['quotation_x'].apply(lambda x: pre_process_document(x))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43337f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
